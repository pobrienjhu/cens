import numpy
import networkx
from networkx.generators.community import *
import logging
import timeit
import SimulationUtils
import copy
import SimulationResults

convergeLimit = 2000
simularityLimit = 5

logger = logging.getLogger('simulate')

# Set the log levels
logger.setLevel(logging.INFO)

# 
# pl = probability of learning
# s = complexity of payoff function
# pt = probability of turnover (per period)
# pe = probability of enviornmental change
#
def simulate(graph, graphData, individuals, reality, pl, s, pt, pe, T, learnTMin, learnTMax, learnTInc, writer, recordEachRun, runToConvergeLimit): 
    
                
        learnTemp = learnTMin
    
        individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
     
        n = len(individuals)
        m = len(reality)
     
        #writer.writerow("########################################################")
     
        individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
        dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
        avgPayoffs = float(sum(individualPayoffs)/len(individualPayoffs))
        prevAvgPayoffs = avgPayoffs
        prevDissimularity = dissimularity     
        simularityCount = 0
             
        logger.info("starting sim for m: |"+str(m)+"| n: |"+str(n)+"| s: |"+str(s)+"| pl: |"+str(pl)+"| T: |"+str(T)+"| pt: |"+str(pt)+"| pe: |"+str(pe)+"| runToConvergeLimit |"+str(runToConvergeLimit)+"|  had average starting dissimularity "+str(dissimularity)+" had average starting payoff "+str(avgPayoffs))
        #logger.debug("starting payoffs are:  "+str(individualPayoffs))
     
        converge = False
        count = 1
        
        writer.writerow(individualPayoffs)   
        writer.writerow([count, avgPayoffs,dissimularity])
        
        while( not converge ):       
            
            if(runToConvergeLimit and count > convergeLimit):
                break
            
            converge = True   
            
            # create a copy of the individual beliefs
            # this is where the changes will be recorded. 
            # HOWEVER learning will take place from the current beliefs
            # thus alowing learning to happen simultaniously for all nodes
            newIndividuals = copy.deepcopy(individuals)          
            
            #logger.debug("graph: "+str(graph))
            #logger.debug("nodes: "+str(graph.nodes()))
                        
            
            #loop through the nodes                             
            for node in graph.nodes():
                #logger.debug("node is "+str(node)+" with neighbors "+str(graph.neighbors(node)))
                
                higherNeighbors = SimulationUtils.findHigherPayoffs(individuals, individualPayoffs, graph.neighbors(node), individualPayoffs[node])
                
                #logger.debug("higherNeighbors: "+str(len(higherNeighbors)))
                
                if(len(higherNeighbors) > 0 ):
                    converge = False
                    concensous = SimulationUtils.findConcensous(higherNeighbors)
                    newIndividuals[node] = SimulationUtils.learn(individuals[node], concensous, pl )
                    #logger.debug("individuals[node]  "+str(individuals[node]))                    
                    #logger.debug("newIndividuals[node]  "+str(newIndividuals[node]))
            #individuals = newIndividuals
            
            # Simulate turnover
            # for pt = 0 the newIndividuals object is simply returned
            individuals = SimulationUtils.turnover(newIndividuals, pt)                                  
            
            
            #logger.debug("iteration |"+str(count)+"| has average payoff "+str(sum(individualPayoffs)/len(individualPayoffs)))
            count += 1    
            
            #simulate a change in reality
            # if T = 0 do not change reality
            if(T != 0 and count % T == 0 ):
                reality = SimulationUtils.changeReality(reality, pe)
            
            #logger.debug("count is "+str(count)+" avgPayoffs is "+str(avgPayoffs))
                  
            individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
            #logger.debug("individualPayoffs: "+str(individualPayoffs))
            
            if(recordEachRun):
                dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
                avgPayoffs = sum(individualPayoffs)/len(individualPayoffs)     
                writer.writerow([count, avgPayoffs,dissimularity,learnTemp])           

                #
                # Check the dissimularity index
                # if it hasn't change start a count
                # if the count hits its limit, either mark as 
                # converged and move on to the next sim, 
                # or reset the learning temperature and keep going. 
                #                              
                if( prevDissimularity == dissimularity and not converge):
                    if(not runToConvergeLimit):
                        logger.info("unchanged dissimularity "+str(dissimularity))  
                    if(simularityLimit == simularityCount ):
                        logger.info("Convergence based on unchanged dissimularity")  
                        converge = True
                        # set the learning temp to the minimum
                        # reset the simularity count
                        learnTemp = learnTMin
                        simularityCount = 0
                    simularityCount += 1  
                else:
                    simularityCount = 0
                    
                prevDissimularity = dissimularity                  
                    
            if(runToConvergeLimit):
                converge = False
   
        dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
        avgPayoffs = sum(individualPayoffs)/len(individualPayoffs)  
        logger.info("converged in |"+str(count-1)+"| had average ending dissimularity "+str(dissimularity)+" had average ending payoff "+str(avgPayoffs))
        writer.writerow([s,m,n,pl,pt,T,pe]+graphData+[count-1,avgPayoffs,dissimularity,individualPayoffs])
