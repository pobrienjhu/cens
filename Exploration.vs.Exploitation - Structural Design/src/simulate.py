import numpy
import networkx
from networkx.generators.community import *
import logging
import timeit
import SimulationUtils
import copy
import SimulationResults

convergeLimit = 1000
simularityLimit = 5

logger = logging.getLogger('simulate')

# Set the log levels
logger.setLevel(logging.INFO)

# 
# pl = probability of learning
# s = complexity of payoff function
# pt = probability of turnover (per period)
# pe = probability of enviornmental change
#
def simulate(graph, graphData, individuals, reality, pl, s, pt, pe, T, writer, recordEachRun, runToConvergeLimit): 
    
        individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
     
        n = len(individuals)
        m = len(reality)
     
        #writer.writerow("########################################################")
     
        individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
        dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
        avgPayoffs = float(sum(individualPayoffs)/len(individualPayoffs))
        prevDissimularity = dissimularity     
        simularityCount = 0
             
        logger.info("starting sim for m: |"+str(m)+"| n: |"+str(n)+"| s: |"+str(s)+"| pl: |"+str(pl)+"| T: |"+str(T)+"| pt: |"+str(pt)+"| pe: |"+str(pe)+"| runToConvergeLimit |"+str(runToConvergeLimit)+"|  had average starting dissimularity "+str(dissimularity)+" had average starting payoff "+str(avgPayoffs))
     
        converge = False
        count = 1
        
        writer.writerow(individualPayoffs)   
        writer.writerow([count, avgPayoffs,dissimularity])
        
        while( not converge ):       
            
            if(count > convergeLimit):
                break
            
            converge = True   
            
            # create a copy of the individual beliefs
            # this is where the changes will be recorded. 
            # HOWEVER learning will take place from the current beliefs
            # thus alowing learning to happen simultaniously for all nodes
            newIndividuals = copy.deepcopy(individuals)          
            
            #loop through the nodes                             
            for node in graph.nodes():
                #logger.info("node is "+str(node)+" with neighbors "+str(graph.neighbors(node)))
                
                higherNeighbors = SimulationUtils.findHigherPayoffs(individuals, individualPayoffs, graph.neighbors(node), individualPayoffs[node])
                
                if(len(higherNeighbors) > 0 ):
                    converge = False
                    concensous = SimulationUtils.findConcensous(higherNeighbors)
                    newIndividuals[node] = SimulationUtils.learn(individuals[node], concensous, pl )
              
            #individuals = newIndividuals
            
            # Simulate turnover
            individuals = SimulationUtils.turnover(newIndividuals, pt)                       
            
            
            #logger.info("iteration |"+str(count)+"| has average payoff "+str(sum(individualPayoffs)/len(individualPayoffs)))
            count += 1    
            
            #simulate a change in reality
            if(count % T == 0 ):
                reality = SimulationUtils.changeReality(reality, pe)
                logger.info("count is "+str(count)+" avgPayoffs is "+str(avgPayoffs))
                  
            individualPayoffs = SimulationUtils.findAllPayoffs(individuals, reality, s)
            
            if(recordEachRun):
                dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
                avgPayoffs = sum(individualPayoffs)/len(individualPayoffs)     
                writer.writerow([count, avgPayoffs,dissimularity])           
        
                if( prevDissimularity == dissimularity and not converge):
                    logger.info("unchanged dissimularity "+str(dissimularity))  
                    if(simularityLimit == simularityCount ):
                        logger.info("Convergence based on unchanged dissimularity")  
                        converge = True
                    simularityCount += 1  
                else:
                    simularityCount = 0
                    
                prevDissimularity = dissimularity   
            
            if(runToConvergeLimit):
                converge = False
   
        dissimularity = SimulationUtils.dissimularity(individuals, m, n) #s, m, n)
        avgPayoffs = sum(individualPayoffs)/len(individualPayoffs)  
        logger.info("converged in |"+str(count-1)+"| had average ending dissimularity "+str(dissimularity)+" had average ending payoff "+str(avgPayoffs))
        writer.writerow([s,m,n,pl,pt,T,pe]+graphData+[count-1,avgPayoffs,dissimularity,individualPayoffs])
